# -*- coding: utf-8 -*-
"""Biopython_Basics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mpyixpcu75rwM17OolBFIogP9kBqpw-T

# ✨✨✨✨ Part 1 BIOPYTHON ✨✨✨✨

# ✨ Installation of Packages ✨
"""

!pip install SeqIO
!pip install biopython

"""# ✨ Task1.1.  What is reverse complement of the DNA sequence 'ATCGGTAATGATAGATGA'? ✨"""

#Task1.1. Work together!

import sys
from Bio.Seq import Seq
# Create a DNA sequence
#Note: Modify the line below to work with the string you want to find the reverse complement for
sequence = Seq("ATCGA")
# Get the reverse complement
reverse_complement = sequence.reverse_complement()
# Print the reverse complement
print(reverse_complement)

"""# ✨ Task1.2 Example of transcription ✨
* What is the RNA transcript of the DNA sequence 'TTCCGATC'? ✨
"""

#Task1.2
from Bio.Seq import Seq
# Create a DNA sequence
#Note: Modify the line below to work with the string you want to find the transcript of.
dna_sequence = Seq("ATCGGTA")
# Perform transcription
rna_sequence = dna_sequence.transcribe()
# Print the RNA sequence
print(rna_sequence)

"""# ✨ Task1.3 Translation in action: Converting DNA/RNA into a Protein Sequence. ✨
* What is the protein sequence encoded by the DNA sequence"ATGCCTAATTTAGATGATGATGATGAAGCTTACGTAGATAGA"? ✨
"""

#Task 1.3
from Bio.Seq import Seq
# Create a DNA sequence (ok)
#Note: Remember what you need to modify in the line below!
dna_sequence = Seq("ATTTAGGATGAACTATGTGTGACAAATGGTGCCGTTGAGTCCTCTCAACTGGGAACGAGTCACCGTGTATCTGGAGACCATGTGTGTAACGGGTTGCACCTGCTTGGCTGGATACAAAGGTGGGATTTCTTTCTGTCTTTGTCATCTCTTAGCAGATTGTATCACATTTTGGCTTAATGCTTACTCAGTCATAAGACAAGTTTCTTTTAC")

# Perform translation to a part of the protein
protein_sequence = dna_sequence.translate()
# Print the protein sequence
print('This is your protein sequence', protein_sequence)

"""# ✨ Remember to place the file "my_sequnce.fasta" into your sample_data folder from this repository https://github.com/bazyliszek/OsloMet2025 to /content/sample_data/ ✨"""

from Bio import SeqIO

# Specify the correct FASTA file path and make sure your file is there
fasta_file = "/content/sample_data/my_sequence.fasta"
#fasta_file = "my_sequence.fasta"

# Read the FASTA file and extract the DNA sequence
for record in SeqIO.parse(fasta_file, "fasta"):
    dna_sequence = record.seq  # Extract the sequence as a Seq object

    # Translate DNA to Protein
    protein_sequence = dna_sequence.translate()

    protein_string = str(protein_sequence)
    proteins = protein_string.split("*")
    # Print the protein sequence
    #print(f"This is my protein sequence: {protein_sequence}")
    for protien in proteins:
      print(protien)

"""# ✨ Task1.4 Find the 3D structure of your favorite genes using AlphaFold: https://alphafold.ebi.ac.uk/ ✨

* How do you think these structures were derived? What is the model confidence for your protein?" ✨
* If you don't have a favorite protein yet, you can explore this one: https://alphafold.ebi.ac.uk/entry/Q9BY14." ✨
* We have been particularly interested in TEX101. You can read more about it here: https://pubmed.ncbi.nlm.nih.gov/35774118/. ✨

# ✨ What is the purpose of sequence alignment? ✨
* Describe this alignment in your own words to your colligue ✨
"""

from Bio import Align
# Create a pairwise sequence aligner
aligner = Align.PairwiseAligner()

# Add sequences to align
seq1 = "ACGTTAGATCTTATT"
seq2 = "TTAGGGAAAAAA"
alignments = aligner.align(seq1, seq2)

# Print the alignments
for alignment in alignments:
    print(alignment)

"""# ✨ Task1.5. Sequence Comparison Using Biopython: What is the match score between the sequences 'ATCGGTATTCA' and 'ATGGTCATTCA'? ✨"""

#Task1.5.
from Bio import pairwise2
from Bio.Seq import Seq

# Create two DNA sequences
seq1 = Seq("ATCGGTATTCA")
seq2 = Seq("ATGGTTTTTCA") #

# Perform pairwise sequence alignment
alignments = pairwise2.align.globalxx(seq1, seq2)

# Print the alignments
for alignment in alignments:
    print(pairwise2.format_alignment(*alignment))

"""# ✨ ✨ ✨  **PART 2 DATABASES** ✨ ✨ ✨ ✨

# ✨ Task2.1.  Access the NCBI database at https://www.ncbi.nlm.nih.gov/  ✨
* What is the length of the sequence NC_000023.11? ✨
"""

#Task2.1.

import sys
# Import the Entrez module from Biopython for accessing NCBI databases
from Bio import Entrez
# Function to fetch genomic sequence using the provided accession number
def fetch_genomic_sequence(accession):
    Entrez.email = "XX.XX@gmail.com"  # Replace with your email address
    # Set the email address to allow NCBI to contact you in case of any issues
    handle = Entrez.efetch(db="nuccore", id=accession, rettype="fasta", retmode="text")
    # 'efetch' is used to fetch the sequence data from the "nuccore" database using the provided accession number.
    # 'rettype="fasta"' specifies that the data should be returned in FASTA format (sequence data).
    # 'retmode="text"' indicates that the data should be returned as a text string.
    record = handle.read()  # Read the fetched sequence data
    handle.close()  # Close the handle to release resources
    return record  # Return the fetched genomic sequence as a string

# Example usage
genomic_accession = "NC_000019.10"  #Replace with the accession number of your genomic sequence of interest NC_000019.10
sequence = fetch_genomic_sequence(genomic_accession)  # Call the function with the accession number to retrieve the sequence
#print(sequence)  # Print the retrieved genomic sequence
print(len(sequence))

"""# ✨ Task2.2.Retrieve the protein sequence and name for the protein with ID 'NP_000508'. ✨

 * What is the length of this protein? What is the name of the protein with ID 'P01308.1'? ✨
"""

#Task2.2.

# Import the Entrez module from Biopython for accessing NCBI databases
from Bio import Entrez

# Function to fetch protein sequence using the provided accession number
def fetch_protein_sequence(accession):
    Entrez.email = "xxx.xxx@gmail.com"  # Replace with your email address
    # Set the email address to allow NCBI to contact you in case of any issues
    handle = Entrez.efetch(db="protein", id=accession, rettype="fasta", retmode="text")
    # 'efetch' is used to fetch the sequence data from the "protein" database using the provided accession number.
    # 'rettype="fasta"' specifies that the data should be returned in FASTA format (sequence data).
    # 'retmode="text"' indicates that the data should be returned as a text string.
    record = handle.read()  # Read the fetched sequence data
    handle.close()  # Close the handle to release resources
    return record  # Return the fetched protein sequence as a string

# Example usage
protein_accession = "NP_000508"  # Replace with the accession number of your protein of interest
sequence = fetch_protein_sequence(protein_accession)  # Call the function with the accession number to retrieve the sequence
print(sequence)  # Print the retrieved protein sequence
print(len(sequence))

"""# ✨ Task2.3  Analyze and explore the mRNA sequence ✨
* To which species and gene does the mRNA ID 'NM_000518' belong? ✨
* How many times has this sequence changed over time?? ✨
"""

#Task2.3
# Import the Entrez module from Biopython for accessing NCBI databases

from Bio import Entrez

# Function to fetch mRNA sequence using the provided accession number
def fetch_mrna_sequence(accession):
    Entrez.email = "marcin.bazyliszek@gmail.com"  # Replace with your email address
    # Set the email address to allow NCBI to contact you in case of any issues
    handle = Entrez.efetch(db="nucleotide", id=accession, rettype="fasta", retmode="text")
    # 'efetch' is used to fetch the sequence data from the "nucleotide" database using the provided accession number.
    # 'rettype="fasta"' specifies that the data should be returned in FASTA format (sequence data).
    # 'retmode="text"' indicates that the data should be returned as a text string.
    record = handle.read()  # Read the fetched sequence data
    handle.close()  # Close the handle to release resources
    return record  # Return the fetched mRNA sequence as a string

# Example usage
mrna_accession = "NM_000518"  # You can also replace with the accession number of your mRNA of interest
sequence = fetch_mrna_sequence(mrna_accession)  # Call the function with the accession number to retrieve the sequence
print(sequence)  # Print the retrieved mRNA sequence

"""# ✨ Task2.4 Can you analyze the differences between version 1 and version 5 of NM_000518? ✨"""

# Task2.4
mrna_accession_1 = "NM_000518.1"
sequence_1 = fetch_mrna_sequence(mrna_accession)
#print(sequence_1)
print('The length of v1 is', len(sequence_1))

mrna_accession_5 = "NM_000518.5"
sequence_5 = fetch_mrna_sequence(mrna_accession_5)
#print(sequence_5)
print('The length of v5 is', len(sequence_5))

from Bio import pairwise2
from Bio.Seq import Seq
alignments = pairwise2.align.globalxx(sequence_1, sequence_5)

for alignment in alignments:
    print(pairwise2.format_alignment(*alignment))
    break

"""# ✨ Task2.5 Retrieve the genomic sequence for accession number 'NM_000518'. ✨

* ✨ Which protein subunit does this sequence correspond to?" ✨
* ✨ Import the Entrez module from Biopython to access NCBI databases for 'NM_000518' ✨
"""

# Task2.5
from Bio import Entrez
# Function to fetch genomic sequence using the provided accession number
def fetch_genomic_sequence(accession):
    Entrez.email = "marcin.bazyliszek@gmail.com"  # Replace with your email address
    # Set the email address to allow NCBI to contact you in case of any issues
    handle = Entrez.efetch(db="nuccore", id=accession, rettype="fasta", retmode="text")
    # 'efetch' is used to fetch the sequence data from the "nuccore" database using the provided accession number.
    # 'rettype="fasta"' specifies that the data should be returned in FASTA format (sequence data).
    # 'retmode="text"' indicates that the data should be returned as a text string.
    record = handle.read()  # Read the fetched sequence data
    handle.close()  # Close the handle to release resources
    return record  # Return the fetched genomic sequence as a string

# Example usage
genomic_accession = "NM_000519"  # Replace with the accession number of your genomic sequence of interest
sequence = fetch_genomic_sequence(genomic_accession)  # Call the function with the accession number to retrieve the sequence
print('This sequence is as following:', sequence)  # Print the retrieved genomic sequence
print(len(sequence))

"""# ✨ Task2.6 Structure Retrival of a protein from Protein Data Bank (PDB) ✨
* How can you open and view a PDB file?
"""

# Task2.6

# Import the PDBList module from Biopython for accessing the Protein Data Bank (PDB)
from Bio.PDB import PDBList

# Function to fetch PDB structure using the provided PDB ID
def fetch_pdb_structure(pdb_id):
    pdbl = PDBList()
    # Create a PDBList object to interact with the PDB database

    pdbl.retrieve_pdb_file(pdb_id, file_format="pdb", pdir="./")
    # Use the retrieve_pdb_file method to fetch the PDB structure with the given PDB ID
    # 'file_format="pdb"' specifies that the data should be returned in PDB format (structure data).
    # 'pdir="./"' indicates that the downloaded PDB file will be saved in the current directory.

    pdb_filename = f"pdb{pdb_id.lower()}.ent"
    # The downloaded PDB file will have a filename in the format "pdbXXXX.ent", where XXXX is the PDB ID in lowercase.

    return pdb_filename  # Return the filename of the downloaded PDB structure


# Example usage
pdb_id = "1CRN"  # Replace with the PDB ID of the structure you want to retrieve (1CRN)
pdb_filename = fetch_pdb_structure(pdb_id)  # Call the function with the PDB ID to retrieve the structure
print(f"PDB structure {pdb_id} downloaded as {pdb_filename}")  # Print the filename of the downloaded PDB structure

#Inspect the file that was created pdb1crn.ent Find out which software you should use for this?

"""# ✨ Task 2.7: Querying the Database for the TEX101 Gene   ✨
* ✨ What are the other known synonyms for this gene?  ✨

"""

# Task2.7
# Import necessary modules from Biopython
from Bio import Entrez, Medline, SeqIO

# Set your email address for NCBI Entrez access
Entrez.email = "marcin.bazyliszek@gmail.com" #use your email account

# Use Entrez to retrieve information about available databases
handle = Entrez.einfo()
rec = Entrez.read(handle)
print(rec)

# Search for nucleotide sequences with gene name "TEX101" from "Homo sapiens" # was CRT and  Plasmodium falciparum
handle = Entrez.esearch(db="nucleotide", term='TEX101[Gene Name] AND "Homo sapiens"[Organism]')
rec_list = Entrez.read(handle)

# If there are more results than the default limit, fetch all results
if int(rec_list['RetMax']) < int(rec_list['Count']):
    handle = Entrez.esearch(db="nucleotide", term='TEX101[Gene Name] AND "Homo sapiens"[Organism]',
                            retmax=rec_list['Count'])
    rec_list = Entrez.read(handle)

# Retrieve the list of matching sequence IDs
id_list = rec_list['IdList']

# Fetch the records corresponding to the retrieved IDs in GenBank format
hdl = Entrez.efetch(db='nucleotide', id=id_list, rettype='gb', retmax=rec_list['Count'])
recs = list(SeqIO.parse(hdl, 'gb'))

# Search for a specific sequence with name "NM_001130011"
for rec in recs:
    if rec.name == 'NM_001130011':  #was KM288867
        break
print(rec.name)
print(rec.description)

# Analyze sequence features
for feature in rec.features:
    if feature.type == 'gene':
        print(feature.qualifiers['gene'])
    elif feature.type == 'exon':
        loc = feature.location
        print('Exon', loc.start, loc.end, loc.strand)
    else:
        print('not processed:\n%s' % feature)

# Print annotations of the retrieved sequence
for name, value in rec.annotations.items():
    print('%s=%s' % (name, value))

# Print the length of the sequence
print(len(rec.seq))

# Retrieve and display the references associated with the sequence
refs = rec.annotations['references']
print(refs)
for ref in refs:
    if ref.pubmed_id != '':
        print(ref.pubmed_id)
        handle = Entrez.efetch(db="pubmed", id=[ref.pubmed_id],
                                rettype="medline", retmode="text")
        records = Medline.parse(handle)
        for med_rec in records:
            for k, v in med_rec.items():
                print('%s: %s' % (k, v))

"""# ✨ Task2.8 Filtering retrieved sequenced data based on length ✨"""

# Task2.8
# Import the SeqIO module from Biopython for parsing sequence data from files
from Bio import SeqIO

# Function to filter sequences based on their length
def filter_sequences_by_length(sequences, min_length):
    filtered_sequences = []  # Create an empty list to store the filtered sequences
    for sequence in sequences:
        if len(sequence) >= min_length:
            # Check if the length of the sequence is greater than or equal to the minimum length
            # If the condition is met, add the sequence to the filtered_sequences list
            filtered_sequences.append(sequence)
    return filtered_sequences  # Return the list of filtered sequences

# Example usage
fasta_file = "sequence.fasta"  # Replace with the filename of your FASTA file containing sequences
fasta_file = "my_sequence.fasta"  # Replace with the filename of your FASTA file containing sequences
fasta_file = "/content/sample_data/my_sequence.fasta"

# https://www.ncbi.nlm.nih.gov/nuccore/NM_001130011.3?report=fasta
min_length = 100  # Set the minimum length for filtering sequences
sequences = SeqIO.parse(fasta_file, "fasta")  # Parse the FASTA file to get a sequence iterator
filtered_sequences = filter_sequences_by_length(sequences, min_length)  # Call the function to filter sequences
for sequence in filtered_sequences:
    print('My fasta file has following sequence', sequence)  # Print the filtered sequences

"""# ✨ Task 2.9 Reading and Writing:  ✨
* What is the ID of the FASTQ file?  ✨
* What is its length? ✨
"""

# Task2.9
from Bio import SeqIO
# Read sequences from a FASTA file
#sequences = SeqIO.parse("sequence.fasta", "fasta")
sequences = SeqIO.parse("/content/sample_data/my_sequence.fasta", "fasta")

# Iterate over the sequences and print their IDs and lengths
for sequence in sequences:
    print("ID:", sequence.id)
    print("Length:", len(sequence))

"""# ✨ ✨ ✨ ✨ ✨ ✨ **PART 3 - RNAseq analysis** ✨"""

!pip install pydeseq2
#!pip install --upgrade numpy
#https://pydeseq2.readthedocs.io/en/stable/
#!pip install --upgrade scikit-learn==1.3.0 scanpy==1.9.3

"""# ✨ Task3.1. What is the dimation of the raw imported count object?  ✨
* Remember to upload the correct file in right direction ✨
* What is ENSG00000271254?
* The file you need you can find it here # https://github.com/bazyliszek/OsloMet2025  ✨
"""

import sys
from pydeseq2.dds import DeseqDataSet
import pandas as pd
from pydeseq2.ds import DeseqStats

counts = pd.read_csv('/content/sample_data/2025_count_table_for_deseq_example.csv')
#counts = pd.read_csv('2025_count_table_for_deseq_example.csv')
print(counts)

counts = counts.set_index('Geneid')
print(counts)

"""# ✨ Task3.2. What is the dimation of the the count object with count more than 0?"""

counts = counts[counts.sum(axis=1) > 0]
print(counts)

counts = counts.T # transformation
print(counts)

""" # ✨ Task3.3. Which contrast you can make in this experiment ✨"""

metadata = pd.DataFrame(zip(counts.index, ['C', 'C', 'C', 'C', 'RS', 'RS', 'RS', 'RS']), columns=['Sample', 'Condition'])
metadata = metadata.set_index('Sample')
print(metadata)

"""# ✨ This object stores the raw count data, metadata (sample information), and the experimental design. ✨

* counts=counts: Provides the raw count matrix (gene expression values for each sample).
* metadata=metadata: Supplies sample metadata, which includes conditions or other experimental factors.
* design_factors="Condition": Specifies that "Condition" is the factor of interest (e.g., control vs. treated samples) for differential expression analysis.
"""

dds = DeseqDataSet(counts=counts, metadata=metadata, design_factors="Condition")
dds.deseq2()
print(dds)

"""# ✨ Purpose in RNA-Seq Analysis ✨

* ✨ This dataset (dds) is used in differential gene expression analysis to compare expression levels between conditions (e.g., treated vs. control). ✨
* ✨ It is then normalized and tested for statistically significant changes in expression. ✨
"""

stat_res = DeseqStats(dds, contrast=['Condition', 'RS', 'C'])
#make summary statistics
stat_res.summary()

res = stat_res.results_df
print(res)

"""# # ✨ Create a Volcano Plot with a Log2 Fold Change Threshold of 2 and alpha of 0.01 ✨
* Explain this graph ✨
* How to show names of the genes that are differentially expressed?
"""

import pandas as pd

# Extract DESeq2 results as a DataFrame
results_df = stat_res.results_df

# Display first few rows
results_df.head()


# Define significance thresholds
alpha = 0.05  # Adjusted p-value threshold
log2fc_threshold = 1  # Fold change threshold

# Add a column for significance
results_df["Significance"] = "Not Significant"
results_df.loc[
    (results_df["padj"] < alpha) & (results_df["log2FoldChange"] > log2fc_threshold), "Significance"
] = "Upregulated"
results_df.loc[
    (results_df["padj"] < alpha) & (results_df["log2FoldChange"] < -log2fc_threshold), "Significance"
] = "Downregulated"

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Convert p-values to -log10(padj) for better visualization
results_df["-log10(padj)"] = -np.log10(results_df["padj"])

# Create the Volcano plot
plt.figure(figsize=(10, 6))
sns.scatterplot(
    x=results_df["log2FoldChange"],
    y=results_df["-log10(padj)"],
    hue=results_df["Significance"],
    palette={"Upregulated": "red", "Downregulated": "blue", "Not Significant": "gray"},
    alpha=0.7
)

# Add axis labels and title
plt.axhline(y=-np.log10(alpha), color="black", linestyle="--", linewidth=1)  # Significance threshold
plt.axvline(x=log2fc_threshold, color="black", linestyle="--", linewidth=1)  # Fold change threshold
plt.axvline(x=-log2fc_threshold, color="black", linestyle="--", linewidth=1)

plt.xlabel("Log2 Fold Change")
plt.ylabel("-Log10 Adjusted P-value")
plt.title("Volcano Plot of Differentially Expressed Genes")
plt.legend(title="Significance")

# Label significant genes
#for i, row in results_df.iterrows():
#    if row["Significance"] in ["Upregulated", "Downregulated"]:
#        plt.text(row["log2FoldChange"], row["-log10(padj)"], row["Symbol"], fontsize=8, ha='right') #row.name

#plt.show()

!pip install sanbomics

from sanbomics.tools import id_map
mapper = id_map(species='human')
res['Symbol'] = res.index.map(mapper.mapper)
res = res[res.baseMean >= 10]

print(res)

sigs = res[(res.padj < 0.05) & (abs(res.log2FoldChange) > 0.5)]
print(sigs)

# Filter significant genes (padj < 0.01 and |log2FC| > 0.5)
sigs = res[(res.padj < 0.01) & (abs(res.log2FoldChange) > 0.5)]

# Sort by absolute log2 fold change in descending order
sigs_sorted = sigs.sort_values(by="log2FoldChange", key=abs, ascending=False)

# Display the top results
sigs_sorted.head()

!pip install scanpy
#!pip install --user scanpy
#!pip install --upgrade numpy scikit-learn scanpy
#!pip install --upgrade scikit-learn==1.3.0 scanpy==1.9.3

!pip install -U scikit-learn ##This works after instaltion   scikit-learn ✨✨✨✨

import scanpy as sc

sc.tl.pca(dds)
sc.pl.pca(dds, color='Condition', size=300)

#import scanpy as sc
#sc.tl.pca(dds, svd_solver='arpack')
#sc.pl.pca(dds, color='Condition', size=200)

"""# ✨ Generate and visualize a clustering analysis ✨"""

import numpy as np
import seaborn as sns
dds.layers['normed_counts']
dds.layers['log1p'] = np.log1p(dds.layers['normed_counts'])
dds.layers['log1p']

print(sigs)
dds_sigs = dds[:, sigs.index]
print(dds_sigs)

grapher = pd.DataFrame(dds_sigs.layers['log1p'].T, index=dds_sigs.var_names, columns=dds_sigs.obs_names)
sns.clustermap(grapher, z_score=0, cmap = 'RdYlBu_r')

"""# Which genes distinguish these 2 condition?

# ✨✨✨  Part IV - Single cell RNA ✨✨

The data used in this basic preprocessing and clustering tutorial was collected from bone marrow mononuclear cells of healthy human donors and was part of openproblem’s NeurIPS 2021 benchmarking dataset [Luecken et al., 2021]. The samples used in this tutorial were measured using the 10X Multiome Gene Expression and Chromatin Accessability kit. credits scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.htm
"""

# Install Core scverse libraries
!pip install -U scikit-learn
!pip install scanpy
!pip install pooch

# Core scverse libraries
import scanpy as sc
import anndata as ad

# Data retrieval
import pooch

sc.settings.set_figure_params(dpi=50, facecolor="white")

"""✨ We are reading in the count matrix into an AnnData object, which holds many slots for annotations and different representations of the data."""

EXAMPLE_DATA = pooch.create(
    path=pooch.os_cache("scverse_tutorials"),
    base_url="doi:10.6084/m9.figshare.22716739.v1/",
)
EXAMPLE_DATA.load_registry_from_doi()

samples = {
    "s1d1": "s1d1_filtered_feature_bc_matrix.h5",
    "s1d3": "s1d3_filtered_feature_bc_matrix.h5",
}
adatas = {}

for sample_id, filename in samples.items():
    path = EXAMPLE_DATA.fetch(filename)
    sample_adata = sc.read_10x_h5(path)
    sample_adata.var_names_make_unique()
    adatas[sample_id] = sample_adata

adata = ad.concat(adatas, label="sample")
adata.obs_names_make_unique()
print(adata.obs["sample"].value_counts())
adata

"""✨ The data contains ~8,000 cells per sample and 36,601 measured genes. We’ll now investigate these with a basic preprocessing and clustering workflow.

# ✨ Quality Control
* The scanpy function calculate_qc_metrics() calculates common quality control (QC) metrics, which are largely based on calculateQCMetrics from scater [McCarthy et al., 2017]. One can pass specific gene population to calculate_qc_metrics() in order to calculate proportions of counts for these populations. Mitochondrial, ribosomal and hemoglobin genes are defined by distinct prefixes as listed below.
"""

# mitochondrial genes, "MT-" for human, "Mt-" for mouse
adata.var["mt"] = adata.var_names.str.startswith("MT-")
# ribosomal genes
adata.var["ribo"] = adata.var_names.str.startswith(("RPS", "RPL"))
# hemoglobin genes
adata.var["hb"] = adata.var_names.str.contains("^HB[^(P)]")

sc.pp.calculate_qc_metrics(
    adata, qc_vars=["mt", "ribo", "hb"], inplace=True, log1p=True
)

"""✨ One can now inspect violin plots of some of the computed QC metrics:
* the number of genes expressed in the count matrix
* the total counts per cell
* the percentage of counts in mitochondrial genes

"""

sc.pl.violin(
    adata,
    ["n_genes_by_counts", "total_counts", "pct_counts_mt"],
    jitter=0.4,
    multi_panel=True,
)

"""✨ Additionally, it is useful to consider QC metrics jointly by inspecting a scatter plot colored by pct_counts_mt."""

sc.pl.scatter(adata, "total_counts", "n_genes_by_counts", color="pct_counts_mt")

"""✨ Based on the QC metric plots, one could now remove cells that have too many mitochondrial genes expressed or too many total counts by setting manual or automatic thresholds. However, sometimes what appears to be poor QC metrics can be driven by real biology so we suggest starting with a very permissive filtering strategy and revisiting it at a later point.
* We therefore now only filter cells with less than 100 genes expressed and genes that are detected in less than 3 cells.

* Additionally, it is important to note that for datasets with multiple batches, quality control should be performed for each sample individually as quality control thresholds can very substantially between batches.
"""

sc.pp.filter_cells(adata, min_genes=100)
sc.pp.filter_genes(adata, min_cells=3)

"""# ✨ Doublet detection
As a next step, we run a doublet detection algorithm. Identifying doublets is crucial as they can lead to misclassifications or distortions in downstream analysis steps. Scanpy contains the doublet detection method Scrublet [Wolock et al., 2019]. Scrublet predicts cell doublets using a nearest-neighbor classifier of observed transcriptomes and simulated doublets. scanpy.pp.scrublet() adds doublet_score and predicted_doublet to .obs. One can now either filter directly on predicted_doublet or use the doublet_score later during clustering to filter clusters with high doublet scores.
"""

sc.pp.scrublet(adata, batch_key="sample")

"""✨ We can remove doublets by either filtering out the cells called as doublets, or waiting until we’ve done a clustering pass and filtering out any clusters with high doublet scores.

# ✨ Normalization
✨ The next preprocessing step is normalization. A common approach is count depth scaling with subsequent log plus one (log1p) transformation. Count depth scaling normalizes the data to a “size factor” such as the median count depth in the dataset, ten thousand (CP10k) or one million (CPM, counts per million). The size factor for count depth scaling can be controlled via target_sum in pp.normalize_total. We are applying median count depth normalization with log1p transformation (AKA log1PF).
"""

5# Saving count data
adata.layers["counts"] = adata.X.copy()

# Normalizing to median total counts
sc.pp.normalize_total(adata)
# Logarithmize the data
sc.pp.log1p(adata)

"""# ✨ Feature selection
✨ As a next step, we want to reduce the dimensionality of the dataset and only include the most informative genes. This step is commonly known as feature selection. The scanpy function pp.highly_variable_genes annotates highly variable genes by reproducing the implementations of Seurat [Satija et al., 2015], Cell Ranger [Zheng et al., 2017], and Seurat v3 [Stuart et al., 2019] depending on the chosen flavor.
"""

sc.pp.highly_variable_genes(adata, n_top_genes=2000, batch_key="sample")

sc.pl.highly_variable_genes(adata)

"""# ✨ Dimensionality Reduction
✨ Reduce the dimensionality of the data by running principal component analysis (PCA), which reveals the main axes of variation and denoises the data.
"""

sc.tl.pca(adata)

""" ✨ Let us inspect the contribution of single PCs to the total variance in the data. This gives us information about how many PCs we should consider in order to compute the neighborhood relations of cells, e.g. used in the clustering function leiden() or tsne(). In our experience, there does not seem to be signifigant downside to overestimating the numer of principal components."""

sc.pl.pca_variance_ratio(adata, n_pcs=50, log=True)

"""✨ You can also plot the principal components to see if there are any potentially undesired features (e.g. batch, QC metrics) driving signifigant variation in this dataset. In this case, there isn’t anything too alarming, but it’s a good idea to explore this."""

sc.pl.pca(
    adata,
    color=["sample", "sample", "pct_counts_mt", "pct_counts_mt"],
    dimensions=[(0, 1), (2, 3), (0, 1), (2, 3)],
    ncols=2,
    size=2,
)

"""#✨ Nearest neighbor graph constuction and visualization
* Let us compute the neighborhood graph of cells using the PCA representation of the data matrix.

"""

sc.pp.neighbors(adata)

"""✨ This graph can then be embedded in two dimensions for visualiztion with UMAP (McInnes et al., 2018):"""

sc.tl.umap(adata)

"""✨ We can now visualize the UMAP according to the sample. ✨"""

sc.pl.umap(
    adata,
    color="sample",
    # Setting a smaller point size to get prevent overlap
    size=2,
)

"""✨ Even though the data considered in this tutorial includes two different samples, we only observe a minor batch effect and we can continue with clustering and annotation of our data.

✨ If you inspect batch effects in your UMAP it can be beneficial to integrate across samples and perform batch correction/integration.

# ✨  Clustering
✨  As with Seurat and many other frameworks, we recommend the Leiden graph-clustering method (community detection based on optimizing modularity) [Traag et al., 2019]. Note that Leiden clustering directly clusters the neighborhood graph of cells, which we already computed in the previous section.
"""

!pip install igraph

# Using the igraph implementation and a fixed number of iterations can be significantly faster, especially for larger datasets
sc.tl.leiden(adata, flavor="igraph", n_iterations=2)

sc.pl.umap(adata, color=["leiden"])

"""# ✨  Re-assess quality control and cell filtering
* As indicated before, we will now re-assess our filtering strategy by visualizing different QC metrics using UMAP. ✨
"""

sc.pl.umap(
    adata,
    color=["leiden", "predicted_doublet", "doublet_score"],
    # increase horizontal space between panels
    wspace=0.5,
    size=3,
)

sc.pl.umap(
    adata,
    color=["leiden", "log1p_total_counts", "pct_counts_mt", "log1p_n_genes_by_counts"],
    wspace=0.5,
    ncols=2,
)

"""# ✨  Manual cell-type annotation ✨

Cell type annotation is laborous and repetitive task, one which typically requires multiple rounds of subclustering and re-annotation. It is difficult to show the entirety of the process in this tutorial, but we aim to show how the tools scanpy provides assist in this process.

We have now reached a point where we have obtained a set of cells with decent quality, and we can proceed to their annotation to known cell types. Typically, this is done using genes that are exclusively expressed by a given cell type, or in other words these genes are the marker genes of the cell types, and are thus used to distinguish the heterogeneous groups of cells in our data. Previous efforts have collected and curated various marker genes into available resources, such as CellMarker, TF-Marker, and PanglaoDB. The cellxgene gene expression tool can also be quite useful to see which cell types a gene has been expressed in across many existing datasets.

Commonly and classically, cell type annotation uses those marker genes subsequent to the grouping of the cells into clusters. So, let’s generate a set of clustering solutions which we can then use to annotate our cell types. Here, we will use the Leiden clustering algorithm which will extract cell communities from our nearest neighbours graph.
"""

for res in [0.02, 0.5, 2.0]:
    sc.tl.leiden(
        adata, key_added=f"leiden_res_{res:4.2f}", resolution=res, flavor="igraph"
    )

"""✨  Notably, the number of clusters that we define is largely arbitrary, and so is the resolution parameter that we use to control for it. As such, the number of clusters is ultimately bound to the stable and biologically-meaningful groups that we can ultimately distringuish, typically done by experts in the corresponding field or by using expert-curated prior knowledge in the form of markers."""

sc.pl.umap(
    adata,
    color=["leiden_res_0.02", "leiden_res_0.50", "leiden_res_2.00"],
    legend_loc="on data",
)

sc.pl.umap(
    adata,
    color=["leiden_res_0.02", "leiden_res_0.50", "leiden_res_2.00"],
    legend_loc="on data",
)

"""✨  Though UMAPs should not be over-interpreted, here we can already see that in the highest resolution our data is over-clustered, while the lowest resolution is likely grouping cells which belong to distinct cell identities.

# ✨  Marker gene set
 ✨ Let’s define a set of marker genes for the main cell types that we expect to see in this dataset. These were adapted from Single Cell Best Practices annotation chapter, for a more detailed overview and best practices in cell type annotation, we refer the user to it.
"""

marker_genes = {
    "CD14+ Mono": ["FCN1", "CD14"],
    "CD16+ Mono": ["TCF7L2", "FCGR3A", "LYN"],
    # Note: DMXL2 should be negative
    "cDC2": ["CST3", "COTL1", "LYZ", "DMXL2", "CLEC10A", "FCER1A"],
    "Erythroblast": ["MKI67", "HBA1", "HBB"],
    # Note HBM and GYPA are negative markers
    "Proerythroblast": ["CDK6", "SYNGR1", "HBM", "GYPA"],
    "NK": ["GNLY", "NKG7", "CD247", "FCER1G", "TYROBP", "KLRG1", "FCGR3A"],
    "ILC": ["ID2", "PLCG2", "GNLY", "SYNE1"],
    "Naive CD20+ B": ["MS4A1", "IL4R", "IGHD", "FCRL1", "IGHM"],
    # Note IGHD and IGHM are negative markers
    "B cells": [
        "MS4A1",
        "ITGB1",
        "COL4A4",
        "PRDM1",
        "IRF4",
        "PAX5",
        "BCL11A",
        "BLK",
        "IGHD",
        "IGHM",
    ],
    "Plasma cells": ["MZB1", "HSP90B1", "FNDC3B", "PRDM1", "IGKC", "JCHAIN"],
    # Note PAX5 is a negative marker
    "Plasmablast": ["XBP1", "PRDM1", "PAX5"],
    "CD4+ T": ["CD4", "IL7R", "TRBC2"],
    "CD8+ T": ["CD8A", "CD8B", "GZMK", "GZMA", "CCL5", "GZMB", "GZMH", "GZMA"],
    "T naive": ["LEF1", "CCR7", "TCF7"],
    "pDC": ["GZMB", "IL3RA", "COBLL1", "TCF4"],
}

sc.pl.dotplot(adata, marker_genes, groupby="leiden_res_0.02", standard_scale="var")

"""✨  There are fairly clear patterns of expression for our markers show here, which we can use to label our coarsest clustering with broad lineages."""

adata.obs["cell_type_lvl1"] = adata.obs["leiden_res_0.02"].map(
    {
        "0": "Lymphocytes",
        "1": "Monocytes",
        "2": "Erythroid",
        "3": "B Cells",
    }
)

sc.pl.dotplot(adata, marker_genes, groupby="leiden_res_0.50", standard_scale="var")

"""✨  This seems like a resolution that suitable to distinguish most of the different cell types in our data. As such, let’s try to annotate those by manually using the dotplot above, together with the UMAP of our clusters. Ideally, one would also look specifically into each cluster, and attempt to subcluster those if required.

# ✨  Differentially-expressed Genes as Markers
✨  Furthermore, one can also calculate marker genes per cluster and then look up whether we can link those marker genes to any known biology, such as cell types and/or states. This is typically done using simple statistical tests, such as Wilcoxon and t-test, for each cluster vs the rest. ✨
"""

# Obtain cluster-specific differentially expressed genes
sc.tl.rank_genes_groups(adata, groupby="leiden_res_0.50", method="wilcoxon")

"""✨  We can then use these genes to figure out what cell types we’re looking at. For example, Cluster 7 is expressing NKG7 and GNLY, suggesting these are NK cells. ✨

✨  To create your own plots, or use a more automated approach, the differentially expressed genes can be extracted in a convenient format with scanpy.get.rank_genes_groups_df() ✨
"""

sc.pl.rank_genes_groups_dotplot(
    adata, groupby="leiden_res_0.50", standard_scale="var", n_genes=5
)

sc.get.rank_genes_groups_df(adata, group="7").head(5)

dc_cluster_genes = sc.get.rank_genes_groups_df(adata, group="7").head(5)["names"]
sc.pl.umap(
    adata,
    color=[*dc_cluster_genes, "leiden_res_0.50"],
    legend_loc="on data",
    frameon=False,
    ncols=3,
)

"""✨  You may have noticed that the p-values found here are extremely low. This is due to the statistical test being performed considering each cell as an independent sample. For a more conservative approach you may want to consider “pseudo-bulking” your data by sample (e.g. sc.get.aggregate(adata, by=["sample", "cell_type"], func="sum", layer="counts")) and using a more powerful differential expression tool, like pydeseq2. ✨"""